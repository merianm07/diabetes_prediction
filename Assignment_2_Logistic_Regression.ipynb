{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e1819bcb",
   "metadata": {},
   "source": [
    "Assignment: Build a Logistic Regression Model for Diabetes Prediction\n",
    "Instructions:\n",
    "Objective: The objective of this assignment is to build a predictive model to predict the likelihood of a patient having diabetes based on certain features.\n",
    "\n",
    "Dataset: You will use the \"diabetes\" dataset provided. The dataset contains information about the medical history of patients, including features like Glucose level, Blood Pressure, BMI, etc., and a target variable indicating whether the patient has diabetes (1) or not (0).\n",
    "\n",
    "Tasks:\n",
    "\n",
    "Explore the dataset to understand its structure and contents.\n",
    "Perform any necessary data preprocessing steps such as handling missing values, encoding categorical variables, and scaling numerical features.\n",
    "Split the dataset into training and testing sets (e.g., 80% training and 20% testing).\n",
    "Build a Logistic Regression model to predict the likelihood of diabetes based on the features provided.\n",
    "Evaluate the model using appropriate metrics such as accuracy, precision, recall, F1-score, and ROC-AUC.\n",
    "Interpret the model coefficients to understand the impact of different features on the likelihood of diabetes.\n",
    "Deliverables:\n",
    "\n",
    "Jupyter Notebook (or Python script) containing the code for data preprocessing, model building, and evaluation.\n",
    "Report summarizing the key findings, model performance metrics, and insights from the model coefficients.\n",
    "Upload the notebook on moodle and github and share the link\n",
    "Submission:\n",
    "\n",
    "Submit the Jupyter Notebook (or Python script) and the report summarizing your analysis.\n",
    "Include any additional insights, visualizations, or improvements you made to the model.\n",
    "Resources:\n",
    "\n",
    "You can refer to Python libraries such as Pandas, NumPy, Scikit-learn for data manipulation, model building, and evaluation.\n",
    "Feel free to reach out for any clarifications or assistance during the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed6fc340",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c242c757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few rows of the dataset:\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6      148             72             35        0  33.6   \n",
      "1            1       85             66             29        0  26.6   \n",
      "2            8      183             64              0        0  23.3   \n",
      "3            1       89             66             23       94  28.1   \n",
      "4            0      137             40             35      168  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  \n",
      "0                     0.627   50        1  \n",
      "1                     0.351   31        0  \n",
      "2                     0.672   32        1  \n",
      "3                     0.167   21        0  \n",
      "4                     2.288   33        1  \n",
      "\n",
      "Dataset Information:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 768 entries, 0 to 767\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Pregnancies               768 non-null    int64  \n",
      " 1   Glucose                   768 non-null    int64  \n",
      " 2   BloodPressure             768 non-null    int64  \n",
      " 3   SkinThickness             768 non-null    int64  \n",
      " 4   Insulin                   768 non-null    int64  \n",
      " 5   BMI                       768 non-null    float64\n",
      " 6   DiabetesPedigreeFunction  768 non-null    float64\n",
      " 7   Age                       768 non-null    int64  \n",
      " 8   Outcome                   768 non-null    int64  \n",
      "dtypes: float64(2), int64(7)\n",
      "memory usage: 54.1 KB\n",
      "None\n",
      "\n",
      "Summary Statistics:\n",
      "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
      "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
      "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
      "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
      "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
      "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
      "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
      "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
      "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
      "\n",
      "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
      "count  768.000000                768.000000  768.000000  768.000000  \n",
      "mean    31.992578                  0.471876   33.240885    0.348958  \n",
      "std      7.884160                  0.331329   11.760232    0.476951  \n",
      "min      0.000000                  0.078000   21.000000    0.000000  \n",
      "25%     27.300000                  0.243750   24.000000    0.000000  \n",
      "50%     32.000000                  0.372500   29.000000    0.000000  \n",
      "75%     36.600000                  0.626250   41.000000    1.000000  \n",
      "max     67.100000                  2.420000   81.000000    1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Load the dataset from a CSV file\n",
    "df = pd.read_csv(\"datasets_228_482_diabetes.csv\")\n",
    "\n",
    "# Display the initial rows of the dataset to get a glimpse\n",
    "print(\"First few rows of the dataset:\")\n",
    "print(df.head())\n",
    "\n",
    "# Check the structure and summary statistics of the dataset\n",
    "print(\"\\nDataset Information:\")\n",
    "print(df.info())\n",
    "print(\"\\nSummary Statistics:\")\n",
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04ed168f",
   "metadata": {},
   "source": [
    "Upon examining the statistics, it becomes evident that certain features, including Glucose, BloodPressure, SkinThickness, Insulin, and BMI, have minimum values of 0. Such occurrences are likely indicative of missing or invalid data, given the implausibility of physiological measurements being zero in most instances.\n",
    "\n",
    "To address this issue, a strategy is devised to replace zero values in the mentioned features with NaN, thereby distinctly marking and isolating them as missing data. Subsequently, the plan involves filling these NaN values with the median, chosen for its robustness to outliers in comparison to the mean. This approach is particularly suitable for physiological measurements, which may occasionally exhibit outliers. Moreover, utilizing the median preserves the overall distribution of the data, ensuring that the substituted values accurately reflect typical data points within the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c4561d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remaining Missing Values:\n",
      "Pregnancies                 0\n",
      "Glucose                     0\n",
      "BloodPressure               0\n",
      "SkinThickness               0\n",
      "Insulin                     0\n",
      "BMI                         0\n",
      "DiabetesPedigreeFunction    0\n",
      "Age                         0\n",
      "Outcome                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Substitute zero values with NaN in specific columns\n",
    "df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']] = df[['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']].replace(0, np.nan)\n",
    "\n",
    "# Fill NaN values with the median of their respective columns\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "# Verify if any missing values persist after the imputation\n",
    "print(\"Remaining Missing Values:\")\n",
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "36613fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into features and the target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Segment the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ebb53e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by subtracting the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Transform the training set using the scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing set using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fe6ccbf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a Logistic Regression model with a specified maximum number of iterations\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model using the standardized training set\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fd61dd99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the standardized testing set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a8d3aa33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.6181818181818182\n",
      "F1 Score: 0.6415094339622642\n",
      "ROC AUC Score: 0.7232323232323232\n"
     ]
    }
   ],
   "source": [
    "# Assess the model's performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97f6106",
   "metadata": {},
   "source": [
    "The logistic regression model has demonstrated an accuracy of approximately 75.32%, signifying its capability to correctly predict whether a patient has diabetes or not in approximately 75% of instances. Furthermore, the precision of the model stands at approximately 66.67%, indicating that when predicting diabetes, the model is accurate around 66.67% of the time. On the other hand, the model's recall is approximately 61.82%, denoting its ability to correctly identify around 61.82% of patients with actual diabetes.\n",
    "\n",
    "The F1 score, a harmonic mean of precision and recall, is approximately 64.15%, reflecting a balanced performance. Additionally, the ROC AUC score, assessing the model's discrimination between positive and negative instances, is around 72.32%. A higher ROC AUC score suggests improved discriminatory ability.\n",
    "\n",
    "In conclusion, the logistic regression model exhibits reasonable performance in various metrics. However, there is room for enhancement, especially in accurately identifying patients with diabetes. Considering the real-world implications of healthcare predictions, minimizing inaccurate predictions is crucial to avoid serious consequences for patients.\n",
    "\n",
    "To enhance the model, potential strategies include feature engineering, exploring existing features, and creating new ones for increased predictive power. Feature selection techniques such as L1 regularization (Lasso) or recursive feature elimination (RFE) could also be employed. Additionally, hyperparameter tuning through methods like grid search or randomized search offers avenues for improvement.\n",
    "\n",
    "To guide the next steps, examining logistic regression coefficients is crucial. This analysis will quantify the impact of independent variables on the target variable, providing insights for further refinement and optimization of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5136b97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Feature  Coefficient\n",
      "1                   Glucose     1.102551\n",
      "5                       BMI     0.688767\n",
      "7                       Age     0.392364\n",
      "0               Pregnancies     0.222844\n",
      "6  DiabetesPedigreeFunction     0.203586\n",
      "3             SkinThickness     0.068664\n",
      "4                   Insulin    -0.138304\n",
      "2             BloodPressure    -0.151521\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the model coefficients\n",
    "coefficients = model.coef_[0]\n",
    "\n",
    "# Construct a DataFrame to showcase feature names and their respective coefficients\n",
    "coef_df = pd.DataFrame({'Feature': X.columns, 'Coefficient': coefficients})\n",
    "coef_df.sort_values(by='Coefficient', ascending=False, inplace=True)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(coef_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d85a239",
   "metadata": {},
   "source": [
    "The logistic regression analysis indicates that Glucose, BMI, Age, and the count of Pregnancies stand out as the most impactful factors in predicting diabetes. Elevated levels of Glucose and BMI, coupled with advancing age and an increased number of pregnancies, contribute to an augmented likelihood of diabetes. The family history of diabetes, represented by DiabetesPedigreeFunction, also holds substantial significance. In contrast, SkinThickness and Insulin exhibit a comparatively minor influence on the model's predictive capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "afc64822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significant Features: ['Glucose', 'BMI', 'Age', 'Pregnancies', 'DiabetesPedigreeFunction']\n",
      "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
      "0            6    148.0           72.0           35.0    125.0  33.6   \n",
      "1            1     85.0           66.0           29.0    125.0  26.6   \n",
      "2            8    183.0           64.0           29.0    125.0  23.3   \n",
      "3            1     89.0           66.0           23.0     94.0  28.1   \n",
      "4            0    137.0           40.0           35.0    168.0  43.1   \n",
      "\n",
      "   DiabetesPedigreeFunction  Age  Outcome  Glucose_BMI  ...  Age_Pregnancies  \\\n",
      "0                     0.627   50        1       4972.8  ...              300   \n",
      "1                     0.351   31        0       2261.0  ...               31   \n",
      "2                     0.672   32        1       4263.9  ...              256   \n",
      "3                     0.167   21        0       2500.9  ...               21   \n",
      "4                     2.288   33        1       5904.7  ...                0   \n",
      "\n",
      "   Age_DiabetesPedigreeFunction  Pregnancies_Glucose  Pregnancies_BMI  \\\n",
      "0                        31.350                888.0            201.6   \n",
      "1                        10.881                 85.0             26.6   \n",
      "2                        21.504               1464.0            186.4   \n",
      "3                         3.507                 89.0             28.1   \n",
      "4                        75.504                  0.0              0.0   \n",
      "\n",
      "   Pregnancies_Age  Pregnancies_DiabetesPedigreeFunction  \\\n",
      "0              300                                 3.762   \n",
      "1               31                                 0.351   \n",
      "2              256                                 5.376   \n",
      "3               21                                 0.167   \n",
      "4                0                                 0.000   \n",
      "\n",
      "   DiabetesPedigreeFunction_Glucose  DiabetesPedigreeFunction_BMI  \\\n",
      "0                            92.796                       21.0672   \n",
      "1                            29.835                        9.3366   \n",
      "2                           122.976                       15.6576   \n",
      "3                            14.863                        4.6927   \n",
      "4                           313.456                       98.6128   \n",
      "\n",
      "   DiabetesPedigreeFunction_Age  DiabetesPedigreeFunction_Pregnancies  \n",
      "0                        31.350                                 3.762  \n",
      "1                        10.881                                 0.351  \n",
      "2                        21.504                                 5.376  \n",
      "3                         3.507                                 0.167  \n",
      "4                        75.504                                 0.000  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Identify significant features based on their coefficients\n",
    "important_features = coef_df[coef_df['Coefficient'].abs() > 0.2]['Feature'].tolist()\n",
    "print(\"Significant Features:\", important_features)\n",
    "\n",
    "# Generate new features considering important features and their interactions\n",
    "for feature in important_features:\n",
    "    # Example: Generating polynomial features\n",
    "    #df[feature + '_squared'] = df[feature] ** 2\n",
    "    # Example: Generating interaction terms with other significant features\n",
    "    for other_feature in important_features:\n",
    "        if other_feature != feature:\n",
    "            df[feature + '_' + other_feature] = df[feature] * df[other_feature]\n",
    "\n",
    "# Verify if new features have been successfully incorporated\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "40d36e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divide the dataset into features and the target variable\n",
    "X = df.drop('Outcome', axis=1)\n",
    "y = df['Outcome']\n",
    "\n",
    "# Segment the dataset into training and testing sets (80% training, 20% testing)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1798d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize features by centering on the mean and scaling to unit variance\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Transform the training set using the scaler\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "# Transform the testing set using the same scaler\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6f2073e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=1000)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct a Logistic Regression model with a specified maximum number of iterations\n",
    "model = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Train the model using the standardized training set\n",
    "model.fit(X_train_scaled, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58b3f842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions on the standardized testing set\n",
    "y_pred = model.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a0ea418b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7532467532467533\n",
      "Precision: 0.660377358490566\n",
      "Recall: 0.6363636363636364\n",
      "F1 Score: 0.6481481481481481\n",
      "ROC AUC Score: 0.7272727272727272\n"
     ]
    }
   ],
   "source": [
    "# Assess the model's performance using various metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Display the evaluation metrics\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae89cd3",
   "metadata": {},
   "source": [
    "Following the implementation of feature engineering, there was only a marginal improvement in performance metrics compared to the initial model. Although precision and ROC AUC score experienced slight increases, the overall accuracy, recall, and F1 score remained relatively consistent. This implies that the employed feature engineering techniques did not result in substantial enhancements in the model's diabetes prediction capability. Further exploration of alternative approaches may be essential to achieve more significant improvements in performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5479286f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'C': 0.1, 'penalty': 'l2'}\n",
      "Best Cross-validation Score: 0.7671331467413035\n",
      "Accuracy: 0.7597402597402597\n",
      "Precision: 0.6730769230769231\n",
      "Recall: 0.6363636363636364\n",
      "F1 Score: 0.6542056074766355\n",
      "ROC AUC Score: 0.7323232323232323\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries for model selection and logistic regression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Instantiate the logistic regression model with a specified maximum number of iterations\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# Define the hyperparameter grid for grid search\n",
    "param_grid = {\n",
    "    'penalty': ['l2'],  # Regularization penalty\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100]  # Inverse regularization strength\n",
    "}\n",
    "\n",
    "# Perform grid search with cross-validation\n",
    "grid_search = GridSearchCV(estimator=logreg, param_grid=param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Fit the grid search to the training data\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Retrieve the best hyperparameters determined by the grid search\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Retrieve the best cross-validation score achieved during grid search\n",
    "best_score = grid_search.best_score_\n",
    "print(\"Best Cross-validation Score:\", best_score)\n",
    "\n",
    "# Retrieve the best model based on cross-validation performance\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Evaluate the best model on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "# Print evaluation metrics for the best model\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"ROC AUC Score:\", roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6725108",
   "metadata": {},
   "source": [
    "After employing grid search to fine-tune hyperparameters, a subtle enhancement was observed in the performance metrics compared to the preceding model. The accuracy increased marginally from 75.32% to 75.97%, and precision saw improvement from 66.04% to 67.31%. However, recall remained constant at 63.64%, and the F1 score showed a slight increase from 64.81% to 65.42%. The ROC AUC score also experienced a minor improvement, progressing from 72.73% to 73.23%.\n",
    "\n",
    "In summary, while grid search effectively optimized the logistic regression model's hyperparameters, the resulting improvements in performance metrics were modest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f3b7ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the pickle module for serialization\n",
    "import pickle\n",
    "\n",
    "# Store the trained model in a pickle file\n",
    "with open('diabetes_lr_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_model, model_file)\n",
    "\n",
    "# Save the scaler to a pickle file\n",
    "with open('diabetes_scaler.pkl', 'wb') as scaler_file:\n",
    "    pickle.dump(scaler, scaler_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
